package main

// This file implements a simpel test for TOAST support on AWS.
//
// TOAST is used by postgres to automagically support large byte arrays (over 8K),
//  https://www.postgresql.org/docs/9.6/static/storage-toast.html
//

import (
	"awstest"
	"flag"
	"fmt"
	"os"
	"os/user"

	"github.com/mgutz/logxi/v1"

	"github.com/jackc/pgx"
)

var dbHost = flag.String("pghost", "", "the host name on which the rds postgres instance can be found")
var dbPort = flag.Int("pgport", 0, "the iport the DB is using on the host on which the rds postgres instance can be found")
var dbUser = flag.String("pguser", "", "the user name to access the postgres instance database")
var dbPassword = flag.String("pgpassword", "", "the password for the pguser that should be used to access the postgres instance")
var dbDatabase = flag.String("pgdatabase", "", "the name of the database that will be used on the postgres instance")
var dbTable = flag.String("pgtable", "oid_table", "the name of the table that will be used in the postgres DB to store our large objects")
var dbMachine = flag.String("pgmachine", "db.t2.medium", "the name of the table that will be used in the postgres DB to store our large objects")

var destroyDB = flag.Bool("cleanup", true, "used to destroy the resources consumed by this test, by default this is true, set to false to lave the rds DB intact")

var cleanup = func(snapshot bool) (err error) { return nil }

func createSchema(cfg pgx.ConnConfig, dbName string, user string) (err error) {

	pool, err := pgx.NewConnPool(
		pgx.ConnPoolConfig{
			ConnConfig:     cfg,
			MaxConnections: 5,
		})
	if err != nil {
		return err
	}

	defer pool.Close()

	// Do a check to see if our test database exists and if so reuse it
	name := ""
	rows, err := pool.Query("select datname from pg_database")
	if err != nil {
		return err
	}
	defer rows.Close()

	for rows.Next() {
		err = rows.Scan(&name)
		if err != nil {
			log.Fatal(fmt.Sprintf("unable to scan a single row column from the rds database %s", err.Error()), "error", err)
			continue
		}

		// Look for a prior copy of the DB
		if name == *dbDatabase {
			return nil
		}
	}

	// No DB was found we will now create one to use for the test
	//
	_, err = pool.Query(fmt.Sprintf("CREATE DATABASE %s OWNER %s", dbName, user))
	return err
}

func main() {

	flag.Parse()

	// Always output the version string, however if the version flag was set by the user then this function
	// will cause the program to exit
	//
	awstest.HandleVersion()

	connCfg := pgx.ConnConfig{
		Host:     *dbHost,
		User:     *dbUser,
		Password: *dbPassword,
		Port:     uint16(*dbPort),
		Database: "postgres",
	}

	// Use a default DB if it was not specified
	if len(*dbDatabase) == 0 && *destroyDB {
		*dbDatabase = "db" + awstest.PseudoUUID()
	}

	// If the destroy option is not enabled then the user must specify a password
	// otherwise they will never be able to access the system
	//
	if !*destroyDB && (len(connCfg.Password) == 0 || len(connCfg.User) == 0 || len(*dbDatabase) == 0) {
		log.Fatal("the database name, user name, or password was not supplied, and the DB is not flagged for destruction, this combination is not valid")
		return
	}

	if len(connCfg.Host) == 0 && connCfg.Port == 0 {

		// use the users name as the AWS DB and resource associated user name so things look somewhat rational if
		// an AWS admin wishes to ask about any left over resources from the test
		if len(connCfg.User) == 0 {
			osAccount, err := user.Current()
			if err != nil {
				osAccount = &user.User{Username: awstest.PseudoUUID()}
			}
			connCfg.User = osAccount.Username
			*dbUser = osAccount.Username

			if len(connCfg.Password) == 0 {
				connCfg.Password = awstest.PseudoUUID()
			}
		}

		// Generate the AWS rds instance as none was supplied
		_, rdsInfo, clean, err := awstest.CreateDB(*dbMachine, 10, connCfg.User, connCfg.Password)

		if err != nil {
			log.Fatal(fmt.Sprintf("%s", err.Error()), "error", err)
		}

		if rdsInfo != nil {
			log.Info(fmt.Sprintf("%v", *rdsInfo))
		}

		// Populate items used to open the DB in the next step of processing
		cleanup = clean
		connCfg.Host = *rdsInfo.Endpoint.Address
		connCfg.Port = uint16(*rdsInfo.Endpoint.Port)
	}

	// Open the DB using the main postgres DB as the name so that we can check for the existance of the
	// test DB either generated by this software, or supplied by the user
	//
	err := createSchema(connCfg, *dbDatabase, *dbUser)
	if err != nil {
		log.Fatal(fmt.Sprintf("unable to perform the DB create due to %s", err.Error()), "error", err)
		os.Exit(1)
	}

	// Calling this will destroy any resources allocated by the createDB including
	// security groups etc.  Calling this is optional as one might wish to keep
	// the DB around after making this request beyond the life of this execution.a
	//
	// Also indicate to the function that no snapshot should be kept for what we are destroying
	//
	if *destroyDB {
		defer func() {
			if err = cleanup(false); err != nil {
				log.Warn(fmt.Sprintf("%s", err.Error()), "error", err)
			}
		}()
	}

	// Close the pool after using the default postgres as a context for creating our main test DB

	// Reopen the DB using the
	connCfg.Database = *dbDatabase
	pool, err := pgx.NewConnPool(
		pgx.ConnPoolConfig{
			ConnConfig:     connCfg,
			MaxConnections: 5,
		})
	if err != nil {
		log.Fatal(fmt.Sprintf("unable to connect to the rds database %s", err.Error()), "error", err)
		os.Exit(1)
	}

	rows, err := pool.Query(fmt.Sprintf("create schema if not exists %s authorization %s", *dbDatabase, *dbUser))
	if err != nil {
		log.Fatal(fmt.Sprintf("unable to create the test schema %s due to %s", *dbDatabase, err.Error()), "error", err)
		os.Exit(-1)
	}
	rows.Close()

	rows, err = pool.Query(fmt.Sprintf("GRANT ALL ON SCHEMA %s TO %s", *dbDatabase, *dbUser))
	if err != nil {
		log.Fatal(fmt.Sprintf("unable to grant access for the test schema %s due to %s", *dbDatabase, err.Error()), "error", err)
		os.Exit(-1)
	}
	rows.Close()

	// Clear the bool used to track if objects needed inside the postgres DB are present
	// so that we can test for the large object table that we wish to use for testing
	//
	dbOK := false
	name := ""

	rows, err = pool.Query("SELECT table_schema || '.' || table_name FROM information_schema.tables WHERE table_type = 'BASE TABLE' AND table_schema NOT IN ('pg_catalog', 'information_schema')")
	if err != nil {
		log.Fatal(fmt.Sprintf("unable to query DB tables due to %s", err.Error()), "error", err)
		os.Exit(1)
	}

	for rows.Next() {
		err := rows.Scan(&name)
		if err != nil {
			log.Fatal(fmt.Sprintf("unable to scan a single row column from the rds database %s", err.Error()), "error", err)
		}
		log.Debug(fmt.Sprintf("Database Table %s present", name))
		if *dbTable == name {
			dbOK = true
			break
		}
	}
	rows.Close()

	// If the needed table for testing the larger than 8K column is missing add it in prior to starting
	// the test
	//
	if !dbOK {
		rows, err = pool.Query(fmt.Sprintf("create table %s ( id text primary key, payload bytea)", *dbTable))
		if err != nil {
			log.Fatal(fmt.Sprintf("unable to create the test table %s due to %s", *dbTable, err.Error()), "error", err)
			os.Exit(-1)
		}

		rows.Close()
		rows, err = pool.Query(fmt.Sprintf("alter table %s set (storage = external), set with oids", *dbTable))
		if err != nil {
			log.Fatal(fmt.Sprintf("unable to set the storage for the test table %s due to %s", *dbTable, err.Error()), "error", err)
			os.Exit(-1)
		}
		rows.Close()

		rows, err = pool.Query(fmt.Sprintf("alter table %s alter column payload set storage external", *dbTable))
		if err != nil {
			log.Fatal(fmt.Sprintf("unable to change column storage within the test table %s due to %s", *dbTable, err.Error()), "error", err)
			os.Exit(-1)
		}
		rows.Close()
	}

	// Create a 40MB buffer with rolling data in it, if you want to simply exercise the API you can use anything
	// above 8K to be larger than the default postgres page size
	//
	binBuffer := make([]byte, 1*1024*1024, 1*1024*1024)
	for i := range binBuffer {
		binBuffer[i] = byte(i & 0xFF)
	}

	log.Debug("using copyTo")
	for i := 1; i <= 100; i++ {
		copied, err := pool.CopyTo(*dbTable, []string{"id", "payload"}, pgx.CopyToRows([][]interface{}{{awstest.PseudoUUID(), binBuffer}}))
		if err != nil {
			log.Fatal(fmt.Sprintf("aws rds postgres CopyTo failed due to %s", err.Error()), "error", err)
			os.Exit(-1)
		}
		if copied != 1 {
			log.Fatal("aws rds postgres CopyTo did not copy all of the rows supplied")
			os.Exit(-1)
		}
	}
	log.Debug("done")
}
